"""
ç”Ÿæˆå„ç§ç±»å‹å’Œå½¢çŠ¶çš„æµ‹è¯•æ•°æ®
ç”¨äºæµ‹è¯• TensorLens æ’ä»¶çš„å„ç§åŠŸèƒ½
"""

import os
import numpy as np
import zipfile
import tarfile
from pathlib import Path

# åˆ›å»ºæµ‹è¯•æ•°æ®ç›®å½•
test_dir = Path(__file__).parent.parent / "test_data"
test_dir.mkdir(exist_ok=True)

print("ğŸš€ å¼€å§‹ç”Ÿæˆæµ‹è¯•æ•°æ®...")
print(f"ğŸ“ è¾“å‡ºç›®å½•: {test_dir}\n")

# ============ NumPy æ•°ç»„æµ‹è¯• ============
print("ğŸ“Š ç”Ÿæˆ NumPy æ•°ç»„...")

# 1. ä¸åŒç»´åº¦çš„æ•°ç»„
np.save(test_dir / "1d_array.npy", np.arange(100))
np.save(test_dir / "2d_matrix.npy", np.random.randn(10, 20))
np.save(test_dir / "3d_tensor.npy", np.random.randn(5, 10, 15))
np.save(test_dir / "4d_batch.npy", np.random.randn(4, 3, 32, 32))  # æ¨¡æ‹Ÿå›¾åƒæ‰¹æ¬¡
np.save(test_dir / "5d_video.npy", np.random.randn(2, 10, 3, 64, 64))  # æ¨¡æ‹Ÿè§†é¢‘

# 2. ä¸åŒæ•°æ®ç±»å‹
np.save(test_dir / "int8_array.npy", np.random.randint(-128, 127, (100,), dtype=np.int8))
np.save(test_dir / "int16_array.npy", np.random.randint(-1000, 1000, (100,), dtype=np.int16))
np.save(test_dir / "int32_array.npy", np.random.randint(-100000, 100000, (100,), dtype=np.int32))
np.save(test_dir / "int64_array.npy", np.random.randint(-1000000, 1000000, (100,), dtype=np.int64))
np.save(test_dir / "uint8_image.npy", np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8))
np.save(test_dir / "float16_array.npy", np.random.randn(100).astype(np.float16))
np.save(test_dir / "float32_array.npy", np.random.randn(100).astype(np.float32))
np.save(test_dir / "float64_array.npy", np.random.randn(100).astype(np.float64))
np.save(test_dir / "bool_array.npy", np.random.choice([True, False], 100))
np.save(test_dir / "complex64_array.npy", np.random.randn(50) + 1j * np.random.randn(50))
np.save(test_dir / "complex128_array.npy", (np.random.randn(50) + 1j * np.random.randn(50)).astype(np.complex128))

# 3. ç‰¹æ®Šå½¢çŠ¶
np.save(test_dir / "scalar.npy", np.array(42.0))
np.save(test_dir / "empty_array.npy", np.array([]))
np.save(test_dir / "single_element.npy", np.array([3.14]))
np.save(test_dir / "huge_1d.npy", np.arange(1000000))  # å¤§æ•°ç»„
np.save(test_dir / "tiny_2d.npy", np.array([[1, 2], [3, 4]]))

# 4. ç‰¹æ®Šå€¼
np.save(test_dir / "with_nan.npy", np.array([1.0, np.nan, 3.0, np.inf, -np.inf]))
np.save(test_dir / "all_zeros.npy", np.zeros((10, 10)))
np.save(test_dir / "all_ones.npy", np.ones((10, 10)))
np.save(test_dir / "identity_matrix.npy", np.eye(20))

# 5. .npz æ–‡ä»¶ï¼ˆå¤šä¸ªæ•°ç»„ï¼‰
np.savez(test_dir / "multiple_arrays.npz",
         train_data=np.random.randn(1000, 784),
         train_labels=np.random.randint(0, 10, 1000),
         test_data=np.random.randn(200, 784),
         test_labels=np.random.randint(0, 10, 200),
         weights=np.random.randn(784, 10),
         bias=np.random.randn(10))

np.savez(test_dir / "image_batch.npz",
         images=np.random.randint(0, 256, (10, 224, 224, 3), dtype=np.uint8),
         labels=np.array(['cat', 'dog', 'bird', 'fish', 'horse', 'car', 'plane', 'ship', 'tree', 'flower']),
         metadata={'source': 'test', 'date': '2026-02-04'})

# 6. .npz å‹ç¼©æ–‡ä»¶
np.savez_compressed(test_dir / "compressed_data.npz",
                    large_matrix=np.random.randn(1000, 1000),
                    sparse_data=np.random.choice([0, 1], (1000, 1000), p=[0.95, 0.05]))

print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.npy')))} ä¸ª .npy æ–‡ä»¶")
print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.npz')))} ä¸ª .npz æ–‡ä»¶")

# ============ PyTorch å¼ é‡æµ‹è¯• ============
try:
    import torch
    print("\nğŸ”¥ ç”Ÿæˆ PyTorch å¼ é‡...")
    
    # 1. åŸºæœ¬å¼ é‡
    torch.save(torch.randn(100), test_dir / "1d_tensor.pt")
    torch.save(torch.randn(10, 20), test_dir / "2d_tensor.pt")
    torch.save(torch.randn(5, 10, 15), test_dir / "3d_tensor.pt")
    torch.save(torch.randn(4, 3, 224, 224), test_dir / "image_batch.pt")  # ImageNetå°ºå¯¸
    torch.save(torch.randn(8, 512, 7, 7), test_dir / "feature_maps.pt")  # CNNç‰¹å¾å›¾
    
    # 2. ä¸åŒæ•°æ®ç±»å‹
    torch.save(torch.randint(-128, 127, (100,), dtype=torch.int8), test_dir / "int8_tensor.pt")
    torch.save(torch.randint(-100, 100, (100,), dtype=torch.int32), test_dir / "int32_tensor.pt")
    torch.save(torch.randint(0, 100, (100,), dtype=torch.int64), test_dir / "int64_tensor.pt")
    torch.save(torch.randn(100).half(), test_dir / "float16_tensor.pt")  # FP16
    torch.save(torch.randn(100), test_dir / "float32_tensor.pt")
    torch.save(torch.randn(100).double(), test_dir / "float64_tensor.pt")
    torch.save(torch.randint(0, 2, (100,), dtype=torch.bool), test_dir / "bool_tensor.pt")
    
    # 3. GPU å¼ é‡ï¼ˆä¼šä¿å­˜ä¸º CPUï¼‰
    if torch.cuda.is_available():
        torch.save(torch.randn(100).cuda(), test_dir / "gpu_tensor.pt")
    
    # 4. æ¨¡å‹æƒé‡å­—å…¸
    model_state = {
        'conv1.weight': torch.randn(64, 3, 7, 7),
        'conv1.bias': torch.randn(64),
        'fc1.weight': torch.randn(1000, 2048),
        'fc1.bias': torch.randn(1000),
        'epoch': 42,
        'accuracy': 0.95
    }
    torch.save(model_state, test_dir / "model_weights.pth")
    
    # 5. å®Œæ•´æ¨¡å‹æ£€æŸ¥ç‚¹
    checkpoint = {
        'model_state_dict': {
            'layer1.weight': torch.randn(128, 64, 3, 3),
            'layer1.bias': torch.randn(128),
            'layer2.weight': torch.randn(256, 128, 3, 3),
            'layer2.bias': torch.randn(256),
        },
        'optimizer_state_dict': {
            'state': {},
            'param_groups': [{'lr': 0.001, 'momentum': 0.9}]
        },
        'epoch': 100,
        'loss': 0.123,
        'best_acc': 0.987
    }
    torch.save(checkpoint, test_dir / "checkpoint.pth")
    
    # 6. å¤æ‚åµŒå¥—ç»“æ„
    complex_data = {
        'tensors': [torch.randn(10, 10) for _ in range(5)],
        'lists': [[1, 2, 3], [4, 5, 6]],
        'nested': {
            'a': torch.randn(5),
            'b': {'c': torch.randn(3, 3), 'd': 'test_string'},
            'e': [torch.randn(2), torch.randn(4)]
        },
        'metadata': {
            'version': '1.0.0',
            'date': '2026-02-04',
            'author': 'TensorLens'
        }
    }
    torch.save(complex_data, test_dir / "complex_structure.pt")
    
    print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.pt')))} ä¸ª .pt æ–‡ä»¶")
    print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.pth')))} ä¸ª .pth æ–‡ä»¶")
    
except ImportError:
    print("\nâš ï¸  PyTorch æœªå®‰è£…ï¼Œè·³è¿‡ .pt/.pth æ–‡ä»¶ç”Ÿæˆ")

# ============ å‹ç¼©æ–‡ä»¶æµ‹è¯• ============
print("\nğŸ“¦ ç”Ÿæˆå‹ç¼©æ–‡ä»¶...")

# 1. ZIP æ–‡ä»¶
with zipfile.ZipFile(test_dir / "sample_archive.zip", 'w') as zf:
    zf.writestr("readme.txt", "This is a test archive created by TensorLens")
    zf.writestr("data/config.json", '{"model": "test", "version": "1.0"}')
    zf.writestr("data/values.txt", "\n".join([str(i) for i in range(100)]))
    # æ·»åŠ ä¸€äº› numpy æ•°æ®
    import io
    buffer = io.BytesIO()
    np.save(buffer, np.random.randn(50, 50))
    zf.writestr("tensors/matrix.npy", buffer.getvalue())

# 2. åŒ…å«å›¾ç‰‡çš„ ZIP
with zipfile.ZipFile(test_dir / "images.zip", 'w') as zf:
    for i in range(5):
        img_data = np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8)
        buffer = io.BytesIO()
        np.save(buffer, img_data)
        zf.writestr(f"images/image_{i:03d}.npy", buffer.getvalue())

# 3. å¤šçº§ç›®å½•ç»“æ„
with zipfile.ZipFile(test_dir / "nested_structure.zip", 'w') as zf:
    zf.writestr("root.txt", "root level")
    zf.writestr("folder1/file1.txt", "content 1")
    zf.writestr("folder1/file2.txt", "content 2")
    zf.writestr("folder1/subfolder/deep.txt", "deep content")
    zf.writestr("folder2/data.txt", "data content")

# 4. TAR æ–‡ä»¶
with tarfile.open(test_dir / "sample_archive.tar", 'w') as tf:
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¹¶æ·»åŠ åˆ° tar
    import tempfile
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as tmp:
        tmp.write("TAR archive test file")
        tmp_path = tmp.name
    tf.add(tmp_path, arcname="test_file.txt")
    os.unlink(tmp_path)

# 5. TAR.GZ æ–‡ä»¶
with tarfile.open(test_dir / "compressed_archive.tar.gz", 'w:gz') as tf:
    with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt') as tmp:
        tmp.write("Compressed TAR.GZ test file\n" * 100)
        tmp_path = tmp.name
    tf.add(tmp_path, arcname="large_text.txt")
    os.unlink(tmp_path)

print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.zip')))} ä¸ª .zip æ–‡ä»¶")
print(f"  âœ“ ç”Ÿæˆ {len(list(test_dir.glob('*.tar*')))} ä¸ª .tar æ–‡ä»¶")

# ============ ç‰¹æ®Šæµ‹è¯•æ–‡ä»¶ ============
print("\nğŸ¯ ç”Ÿæˆç‰¹æ®Šæµ‹è¯•æ–‡ä»¶...")

# 1. è¶…å¤§æ–‡ä»¶ï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰
np.save(test_dir / "large_10mb.npy", np.random.randn(1000, 1000))  # ~8MB

# 2. è¶…å°æ–‡ä»¶
np.save(test_dir / "tiny.npy", np.array([1]))

# 3. æ–‡ä»¶ååŒ…å«ç‰¹æ®Šå­—ç¬¦
np.save(test_dir / "å¸¦ä¸­æ–‡åç§°çš„æ–‡ä»¶.npy", np.random.randn(10, 10))
np.save(test_dir / "file with spaces.npy", np.random.randn(5, 5))
np.save(test_dir / "file-with-dashes.npy", np.random.randn(5, 5))
np.save(test_dir / "file_with_underscores.npy", np.random.randn(5, 5))

# 4. ç»“æ„åŒ–æ•°ç»„
dt = np.dtype([('name', 'U10'), ('age', 'i4'), ('weight', 'f4')])
structured = np.array([
    ('Alice', 25, 55.5),
    ('Bob', 30, 75.2),
    ('Charlie', 35, 68.9)
], dtype=dt)
np.save(test_dir / "structured_array.npy", structured)

# 5. è®°å½•æ•°ç»„
record = np.rec.array([
    ('Alice', 25, 165.5),
    ('Bob', 30, 175.2),
    ('Charlie', 35, 180.0)
], dtype=[('name', 'U10'), ('age', 'i4'), ('height', 'f4')])
np.save(test_dir / "record_array.npy", record)

print("  âœ“ ç”Ÿæˆç‰¹æ®Šæµ‹è¯•æ–‡ä»¶")

# ============ ç»Ÿè®¡ä¿¡æ¯ ============
print("\n" + "="*60)
print("ğŸ“Š ç”Ÿæˆå®Œæˆç»Ÿè®¡:")
print("="*60)

total_size = sum(f.stat().st_size for f in test_dir.iterdir() if f.is_file())
file_counts = {
    '.npy': len(list(test_dir.glob('*.npy'))),
    '.npz': len(list(test_dir.glob('*.npz'))),
    '.pt': len(list(test_dir.glob('*.pt'))),
    '.pth': len(list(test_dir.glob('*.pth'))),
    '.zip': len(list(test_dir.glob('*.zip'))),
    '.tar*': len(list(test_dir.glob('*.tar*')))
}

for ext, count in file_counts.items():
    if count > 0:
        print(f"  {ext:8s}: {count:3d} ä¸ªæ–‡ä»¶")

print(f"\n  æ€»å¤§å°: {total_size / (1024*1024):.2f} MB")
print(f"  æ€»æ–‡ä»¶æ•°: {sum(file_counts.values())} ä¸ª")
print(f"\nğŸ“ æ‰€æœ‰æ–‡ä»¶ä½äº: {test_dir.absolute()}")
print("\nâœ¨ æµ‹è¯•æ•°æ®ç”Ÿæˆå®Œæˆï¼ç°åœ¨å¯ä»¥ç”¨ TensorLens æ‰“å¼€è¿™äº›æ–‡ä»¶è¿›è¡Œæµ‹è¯•äº†ã€‚")
